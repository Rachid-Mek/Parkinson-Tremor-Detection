{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bayesian-optimization in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from bayesian-optimization) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.25 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from bayesian-optimization) (2.0.2)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from bayesian-optimization) (1.5.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from bayesian-optimization) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting mlxtend\n",
      "  Using cached mlxtend-0.23.3-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from mlxtend) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from mlxtend) (2.0.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from mlxtend) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from mlxtend) (1.5.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from mlxtend) (3.9.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rachi\\bureau\\ia2s & gp\\mini_projet\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Using cached mlxtend-0.23.3-py3-none-any.whl (1.4 MB)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bayesian-optimization\n",
    "%pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_excel('Data_Preprocessed1/1.xlsx')\n",
    "data2 = pd.read_excel('Data_Preprocessed1/2.xlsx')\n",
    "data3 = pd.read_excel('Data_Preprocessed1/3.xlsx')\n",
    "data4 = pd.read_excel('Data_Preprocessed1/4.xlsx')\n",
    "data5 = pd.read_excel('Data_Preprocessed1/5.xlsx')\n",
    "\n",
    "dataset = [data1,data2,data3,data4,data5]\n",
    "i = 1\n",
    "for data in dataset:\n",
    "    data.dropna(inplace=True)\n",
    "    # save the data\n",
    "    data.to_excel('Data_Preprocessed1/'+str(i)+'.xlsx', index=False)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [data1,data2,data3,data4,data5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(window):\n",
    "    ax = window['ax'].mean()\n",
    "    ay = window['ay'].mean()\n",
    "    az = window['az'].mean()\n",
    "    return ax, ay, az\n",
    "\n",
    "def root_mean_square(window):\n",
    "    rms_ax = np.sqrt(np.mean(window['ax']**2))\n",
    "    rms_ay = np.sqrt(np.mean(window['ay']**2))\n",
    "    rms_az = np.sqrt(np.mean(window['az']**2))\n",
    "    return rms_ax, rms_ay, rms_az\n",
    "\n",
    "def standard_deviation(window):\n",
    "    std_ax = np.std(window['ax'])\n",
    "    std_ay = np.std(window['ay'])\n",
    "    std_az = np.std(window['az'])\n",
    "    return std_ax, std_ay, std_az\n",
    "\n",
    "def signal_magnitude_vector(window):\n",
    "    return np.sqrt(window['ax']**2 + window['ay']**2 + window['az']**2)\n",
    "\n",
    "def interquartile_range(window):\n",
    "    iqr_ax = window['ax'].quantile(0.75) - window['ax'].quantile(0.25)\n",
    "    iqr_ay = window['ay'].quantile(0.75) - window['ay'].quantile(0.25)\n",
    "    iqr_az = window['az'].quantile(0.75) - window['az'].quantile(0.25)\n",
    "    return iqr_ax, iqr_ay, iqr_az\n",
    "\n",
    "def max_min(window):\n",
    "    max_ax = window['ax'].max() - window['ax'].min()\n",
    "    max_ay = window['ay'].max() - window['ay'].min()\n",
    "    max_az = window['az'].max() - window['az'].min()\n",
    "    return max_ax, max_ay, max_az\n",
    "\n",
    "def kurtosis(window):\n",
    "    kurtosis_ax = window['ax'].kurtosis()\n",
    "    kurtosis_ay = window['ay'].kurtosis()\n",
    "    kurtosis_az = window['az'].kurtosis()\n",
    "    return kurtosis_ax, kurtosis_ay, kurtosis_az\n",
    "\n",
    "def skewness(window):\n",
    "    skewness_ax = window['ax'].skew()\n",
    "    skewness_ay = window['ay'].skew()\n",
    "    skewness_az = window['az'].skew()\n",
    "    return skewness_ax, skewness_ay, skewness_az\n",
    "\n",
    "def mean_frequency_power(window):\n",
    "    freq_ax = np.mean(np.abs(fft(window['ax'])))\n",
    "    freq_ay = np.mean(np.abs(fft(window['ay'])))\n",
    "    freq_az = np.mean(np.abs(fft(window['az'])))\n",
    "    return freq_ax, freq_ay, freq_az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_window_feature_extraction(data, window_size, step_size=1):\n",
    "\n",
    "    features_list = []\n",
    "    total_samples = len(data)\n",
    "\n",
    "    # Itération sur les fenêtres\n",
    "    for start in range(0, total_samples - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        window = data.iloc[start:end]\n",
    "\n",
    "        mean_values = mean(window)\n",
    "        rms_values = root_mean_square(window)\n",
    "        std_values = standard_deviation(window)\n",
    "        iqr_values = interquartile_range(window)\n",
    "        max_min_values = max_min(window)\n",
    "        mean_freq_power_values = mean_frequency_power(window)\n",
    "\n",
    "        smv_values = signal_magnitude_vector(window)\n",
    "        smv_mean = smv_values.mean()\n",
    "\n",
    "        features = {\n",
    "            'start_index': start,\n",
    "            'end_index': end,\n",
    "            'mean_ax': mean_values[0],\n",
    "            'mean_ay': mean_values[1],\n",
    "            'mean_az': mean_values[2],\n",
    "            'rms_ax': rms_values[0],\n",
    "            'rms_ay': rms_values[1],\n",
    "            'rms_az': rms_values[2],\n",
    "            'std_ax': std_values[0],\n",
    "            'std_ay': std_values[1],\n",
    "            'std_az': std_values[2],\n",
    "            'smv_mean': smv_mean,\n",
    "            'smv_max' : smv_values.max(),\n",
    "            'smv_min' : smv_values.min(),\n",
    "            'iqr_ax': iqr_values[0],\n",
    "            'iqr_ay': iqr_values[1],\n",
    "            'iqr_az': iqr_values[2],\n",
    "            'max_min_ax': max_min_values[0],\n",
    "            'max_min_ay': max_min_values[1],\n",
    "            'max_min_az': max_min_values[2],\n",
    "            'mean_freq_power_ax': mean_freq_power_values[0],\n",
    "            'mean_freq_power_ay': mean_freq_power_values[1],\n",
    "            'mean_freq_power_az': mean_freq_power_values[2],\n",
    "            'label' : window['label'].mode().values[0] \n",
    "        }\n",
    "\n",
    "        features_list.append(features)\n",
    "\n",
    "    # Conversion en DataFrame\n",
    "    features_df = pd.DataFrame(features_list)\n",
    "\n",
    "    return features_df\n",
    "\n",
    "def preprocess_data(data, window_size, step_size):\n",
    "    for i in range(len(data)):\n",
    "        features_df = moving_window_feature_extraction(data[i], window_size, step_size)\n",
    "        features_df.to_csv('Data_Preprocessed1/data_'+str(i+1)+'.csv', index=False)\n",
    "\n",
    "window_size = 50\n",
    "step_size = 1\n",
    "preprocess_data(dataset, window_size, step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé : New_Data/1.csv\n",
      "Fichier sauvegardé : New_Data/2.csv\n",
      "Fichier sauvegardé : New_Data/3.csv\n",
      "Fichier sauvegardé : New_Data/4.csv\n",
      "Fichier sauvegardé : New_Data/5.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Dossiers des fichiers d'entrée et de sortie\n",
    "data_folder = \"Data/\"\n",
    "output_folder = \"New_Data/\"\n",
    "\n",
    "# Assurer que le dossier de sortie existe\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Liste des fichiers Excel à traiter (1.xlsx à 5.xlsx)\n",
    "file_names = [f\"{i}.xlsx\" for i in range(1, 6)]\n",
    "\n",
    "# Lire chaque fichier, transformer et sauvegarder\n",
    "for file in file_names:\n",
    "    file_path = os.path.join(data_folder, file)\n",
    "\n",
    "    # Lire le fichier Excel\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Transformer les données en format (acc, label)\n",
    "    df_transformed = pd.DataFrame({\n",
    "        'acc': pd.concat([df['ax'], df['ay'], df['az']], ignore_index=True),\n",
    "        'label': pd.concat([df['lx'], df['ly'], df['lz']], ignore_index=True)\n",
    "    })\n",
    "\n",
    "    # Définir le chemin du fichier de sortie\n",
    "    output_file = os.path.join(output_folder, file.replace('.xlsx', '.csv'))\n",
    "\n",
    "    df_transformed.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Fichier sauvegardé : {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prétraitement terminé. Les fichiers sont sauvegardés dans New_Data/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft\n",
    "\n",
    "# Chemins des dossiers\n",
    "data_folder = \"New_Data/\"\n",
    "output_folder = \"New_Data/\"\n",
    "\n",
    "# Assurer que le dossier de sortie existe\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Charger les fichiers CSV depuis `New_Data/`\n",
    "file_names = [f\"{i}.csv\" for i in range(1, 6)]\n",
    "dataset = [pd.read_csv(os.path.join(data_folder, file)) for file in file_names]\n",
    "\n",
    "# Nettoyage des données (suppression des valeurs NaN)\n",
    "for i, data in enumerate(dataset, start=1):\n",
    "    data.dropna(inplace=True)\n",
    "    data.to_csv(os.path.join(output_folder, f\"{i}.csv\"), index=False)\n",
    "\n",
    "# Définition des fonctions d'extraction de caractéristiques\n",
    "def mean(window):\n",
    "    return window['acc'].mean()\n",
    "\n",
    "def root_mean_square(window):\n",
    "    return np.sqrt(np.mean(window['acc']**2))\n",
    "\n",
    "def standard_deviation(window):\n",
    "    return np.std(window['acc'])\n",
    "\n",
    "def interquartile_range(window):\n",
    "    return window['acc'].quantile(0.75) - window['acc'].quantile(0.25)\n",
    "\n",
    "def max_min(window):\n",
    "    return window['acc'].max() - window['acc'].min()\n",
    "\n",
    "def mean_frequency_power(window):\n",
    "    return np.mean(np.abs(fft(window['acc'])))\n",
    "\n",
    "def moving_window_feature_extraction(data, window_size, step_size=1):\n",
    "    features_list = []\n",
    "    total_samples = len(data)\n",
    "\n",
    "    # Itération sur les fenêtres\n",
    "    for start in range(0, total_samples - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        window = data.iloc[start:end]\n",
    "\n",
    "        features = {\n",
    "            'start_index': start,\n",
    "            'end_index': end,\n",
    "            'mean_acc': mean(window),\n",
    "            'rms_acc': root_mean_square(window),\n",
    "            'std_acc': standard_deviation(window),\n",
    "            'iqr_acc': interquartile_range(window),\n",
    "            'max_min_acc': max_min(window),\n",
    "            'mean_freq_power_acc': mean_frequency_power(window),\n",
    "            'label': window['label'].mode().values[0]  # Label le plus fréquent dans la fenêtre\n",
    "        }\n",
    "\n",
    "        features_list.append(features)\n",
    "\n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "def preprocess_data(dataset, window_size, step_size):\n",
    "    for i, data in enumerate(dataset, start=1):\n",
    "        features_df = moving_window_feature_extraction(data, window_size, step_size)\n",
    "        features_df.to_csv(os.path.join(output_folder, f\"data_{i}.csv\"), index=False)\n",
    "\n",
    "# Paramètres\n",
    "window_size = 50\n",
    "step_size = 1\n",
    "\n",
    "# Exécution du prétraitement\n",
    "preprocess_data(dataset, window_size, step_size)\n",
    "\n",
    "print(\"Prétraitement terminé. Les fichiers sont sauvegardés dans\", output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
